@misc{enwiki:1044966507,
  author = {{Wikipedia contributors}},
  title  = {COVID-19 pandemic by country and territory --- {Wikipedia}{,} The Free Encyclopedia},
  year   = {2021},
  url    = {https://en.wikipedia.org/w/index.php?title=COVID-19_pandemic_by_country_and_territory&oldid=1044966507},
  note   = {[Online; accessed 19-September-2021]}
}

@misc{PPR:PPR343330,
  title     = {Exploring Self-Supervised Representation Ensembles for COVID-19 Cough Classification},
  author    = {Xue, Hao and Salim, Flora},
  publisher = {arXiv},
  year      = {2021},
  url       = {https://arxiv.org/abs/2105.07566v1}
}

@article{sharma2020coswara,
  title   = {Coswara--A Database of Breathing, Cough, and Voice Sounds for COVID-19 Diagnosis},
  author  = {Sharma, Neeraj and Krishnan, Prashant and Kumar, Rohit and Ramoji, Shreyas and Chetupalli, Srikanth Raj and Ghosh, Prasanta Kumar and Ganapathy, Sriram and others},
  journal = {arXiv preprint arXiv:2005.10548},
  year    = {2020}
}


@article{mohammed2021ensemble,
  title     = {An ensemble learning approach to digital corona virus preliminary screening from cough sounds},
  author    = {Mohammed, Emad A and Keyhani, Mohammad and Sanati-Nezhad, Amir and Hejazi, S Hossein and Far, Behrouz H},
  journal   = {Scientific Reports},
  volume    = {11},
  number    = {1},
  pages     = {1--11},
  year      = {2021},
  publisher = {Nature Publishing Group}
}

@article{pahar2021covid,
  title     = {COVID-19 Cough Classification using Machine Learning and Global Smartphone Recordings★},
  author    = {Pahar, Madhurananda and Klopper, Marisa and Warren, Robin and Niesler, Thomas},
  journal   = {Computers in Biology and Medicine},
  pages     = {104572},
  year      = {2021},
  publisher = {Elsevier}
}


@article{aly2021pay,
  title     = {Pay Attention to the Speech: COVID-19 Diagnosis using Machine Learning and Crowdsourced Respiratory and Speech Recordings},
  author    = {Aly, Mahmoud and Rahouma, Kamel H and Ramzy, Safwat M},
  journal   = {Alexandria Engineering Journal},
  year      = {2021},
  publisher = {Elsevier}
}


@article{girin2020dynamical,
  title   = {Dynamical variational autoencoders: A comprehensive review},
  author  = {Girin, Laurent and Leglaive, Simon and Bie, Xiaoyu and Diard, Julien and Hueber, Thomas and Alameda-Pineda, Xavier},
  journal = {arXiv preprint arXiv:2008.12595},
  year    = {2020}
}

@article{hossin2015review,
  title     = {A review on evaluation metrics for data classification evaluations},
  author    = {Hossin, Mohammad and Sulaiman, Md Nasir},
  journal   = {International journal of data mining \& knowledge management process},
  volume    = {5},
  number    = {2},
  pages     = {1},
  year      = {2015},
  publisher = {Academy \& Industry Research Collaboration Center (AIRCC)}
}


@article{paszke2019pytorch,
  title   = {Pytorch: An imperative style, high-performance deep learning library},
  author  = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal = {Advances in neural information processing systems},
  volume  = {32},
  pages   = {8026--8037},
  year    = {2019}
}

@book{geron2019hands,
  title     = {Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build intelligent systems},
  author    = {G{\'e}ron, Aur{\'e}lien},
  year      = {2019},
  publisher = {O'Reilly Media}
}

@inproceedings{cho-etal-2014-properties,
  title     = {On the Properties of Neural Machine Translation: Encoder{--}Decoder Approaches},
  author    = {Cho, Kyunghyun  and
      van Merri{\"e}nboer, Bart  and
      Bahdanau, Dzmitry  and
      Bengio, Yoshua},
  booktitle = {Proceedings of {SSST}-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation},
  month     = oct,
  year      = {2014},
  address   = {Doha, Qatar},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W14-4012},
  doi       = {10.3115/v1/W14-4012},
  pages     = {103--111}
}
@inproceedings{Wang2nd,
  title     = {Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author    = {Junyoung Chung and Caglar Gulcehre and Kyunghyun Cho and Yoshua Bengio},
  year      = {2014},
  language  = {English (US)},
  booktitle = {NIPS 2014 Workshop on Deep Learning, December 2014}
}

@inproceedings{Yang1st,
  author    = {Hassan, Abdelfatah and Shahin, Ismail and Alsabek, Mohamed Bader},
  booktitle = {2020 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)},
  title     = {COVID-19 Detection System using Recurrent Neural Networks},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {1-5},
  doi       = {10.1109/CCCI49893.2020.9256562}
}

@article{Yang2nd,
  author  = {Pahar, Madhurananda and Klopper, Marisa and Warren, Robin and Niesler, Thomas},
  year    = {2021},
  month   = {06},
  pages   = {104572},
  title   = {COVID-19 Cough Classification using Machine Learning and Global Smartphone Recordings},
  volume  = {135},
  journal = {Computers in Biology and Medicine},
  doi     = {10.1016/j.compbiomed.2021.104572}
}

@article{Yang4th,
  author   = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  title    = {{Long Short-Term Memory}},
  journal  = {Neural Computation},
  volume   = {9},
  number   = {8},
  pages    = {1735-1780},
  year     = {1997},
  month    = {11},
  abstract = {{Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.}},
  issn     = {0899-7667},
  doi      = {10.1162/neco.1997.9.8.1735},
  url      = {https://doi.org/10.1162/neco.1997.9.8.1735},
  eprint   = {https://direct.mit.edu/neco/article-pdf/9/8/1735/813796/neco.1997.9.8.1735.pdf}
}

@inproceedings{Yang5th,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Attention is All you Need},
  url       = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
  volume    = {30},
  year      = {2017}
}

@incollection{Chao1st,
  title     = {CNN Architectures for Large-Scale Audio Classification},
  author    = {Shawn Hershey and Sourish Chaudhuri and Daniel P. W. Ellis and Jort F. Gemmeke and Aren Jansen and Channing Moore and Manoj Plakal and Devin Platt and Rif A. Saurous and Bryan Seybold and Malcolm Slaney and Ron Weiss and Kevin Wilson},
  year      = {2017},
  url       = {https://arxiv.org/abs/1609.09430},
  booktitle = {International Conference on Acoustics, Speech and Signal Processing (ICASSP)}
}
@misc{Chao2nd,
  title         = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  author        = {Karen Simonyan and Andrew Zisserman},
  year          = {2015},
  eprint        = {1409.1556},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{Chao3rd,
  title     = {Audio Set: An ontology and human-labeled dataset for audio events},
  author    = {Jort F. Gemmeke and Daniel P. W. Ellis and Dylan Freedman and Aren Jansen and Wade Lawrence and R. Channing Moore and Manoj Plakal and Marvin Ritter},
  year      = {2017},
  booktitle = {Proc. IEEE ICASSP 2017},
  address   = {New Orleans, LA}
}

@article{Chao5th,
  title   = {Lung Sound Recognition Algorithm Based on VGGish-BiGRU},
  author  = {Lukui Shi and Kang Du and Chaozong Zhang and Hongqi Ma and Wenjie Yan},
  journal = {IEEE Access},
  year    = {2019},
  volume  = {7},
  pages   = {139438-139449}
}


